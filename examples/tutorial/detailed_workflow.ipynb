{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac18d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright (c) Microsoft Corporation.\n",
    "#  Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33410e2",
   "metadata": {},
   "source": [
    "这个 Jupyter Notebook (detailed_workflow.ipynb) 的目的是详细展示如何一步步使用 Qlib 构建量化研究的各个组件。当你运行完整个 Notebook 后，会产生以下类型的输出和结果：\n",
    "\n",
    "1.  **数据下载与初始化信息**：\n",
    "    *   单元格 `[In] GetData().qlib_data(exists_skip=True)` 会检查并下载 Qlib 所需的示例数据（如果本地没有的话），并输出下载进度或跳过信息。\n",
    "    *   单元格 `[In] qlib.init()` 会初始化 Qlib 的运行环境，可能会输出 Qlib 的版本信息或数据存储路径。\n",
    "\n",
    "2.  **原始数据探查**：\n",
    "    *   **日历数据**：输出指定时间段内的交易日历（例如，前两条记录）。\n",
    "    *   **基础行情数据**：\n",
    "        *   输出特定股票（如 \"SH601216\"）在指定时间段内的开盘价、最高价、最低价、收盘价和复权因子 (`$open`, `$high`, `$low`, `$close`, `$factor`) 的 DataFrame。\n",
    "        *   生成并显示该股票的**K线图** (Candlestick chart)。\n",
    "        *   生成并显示经过**复权因子调整后的K线图**，展示真实的价格变动。\n",
    "    *   **动态股票池 (Dynamic Universe)**：\n",
    "        *   输出 CSI100 指数在指定时间段内每天包含的股票列表。\n",
    "        *   输出股票池中股票数量的统计信息。\n",
    "        *   生成并显示 CSI100 指数成分股数量随时间变化的**折线图**。\n",
    "    *   **Point-In-Time (PIT) 财务数据**：\n",
    "        *   如果本地没有 PIT 数据，会执行脚本下载和处理特定股票（如茅台 \"600519\" 和京东方A \"000725\"）的季度财务数据，并输出相关命令的执行日志。\n",
    "        *   查询并输出特定股票（如 \"sh600519\"）在指定时间段内每日的最新季度财报数据（例如，`$$roewa_q` 净资产收益率），通常会显示一个包含 NaN 值并在财报发布日更新数据的 DataFrame。\n",
    "\n",
    "3.  **表达式引擎 (Express Engine)**：\n",
    "    *   输出使用 Qlib 表达式计算的技术指标结果（例如，MACD 指标的某个变种）的 DataFrame。\n",
    "\n",
    "4.  **数据集加载与预处理**：\n",
    "    *   **数据加载器 (QlibDataLoader)**：\n",
    "        *   输出使用 `QlibDataLoader` 加载的特定特征（如10日收益率 \"RET10\"）的 DataFrame。\n",
    "    *   **数据处理器 (DataHandlerLP)**：\n",
    "        *   对加载的数据进行预处理（如Z-Score标准化、缺失值填充）后，输出处理后数据的 DataFrame。\n",
    "        *   输出处理前后数据的缺失值统计 (`df.isna().sum()`)。\n",
    "        *   生成并显示处理前后数据的**直方图**，以观察数据分布的变化。\n",
    "    *   **数据集 (Dataset)**：\n",
    "        *   **基础数据集 (DatasetH)**：准备训练集和验证集后，不会直接输出整个数据集，但后续模型会使用它。\n",
    "        *   **时间序列数据集 (TSDatasetH)**：\n",
    "            *   输出 `train_sampler` 对象本身的信息。\n",
    "            *   输出从 `train_sampler` 中获取的第一个样本（一个时间序列片段）。\n",
    "            *   输出通过 `<'timestamp', 'instrument_id'>` 索引获取的特定时间序列样本。\n",
    "    *   **现成数据集 (Off-the-shelf dataset - Alpha158)**：\n",
    "        *   输出 `Alpha158` handler 的配置字典。\n",
    "        *   输出通过 `Alpha158` handler 获取的特征 DataFrame (包含158个alpha因子)。\n",
    "        *   输出 `Alpha158` handler 的 `data_loader` 对象及其包含的 `fields`。\n",
    "        *   输出 `learn_processors` 和 `infer_processors`（学习阶段和推断阶段使用的数据处理器列表）。\n",
    "        *   输出 `process_type` (数据处理类型)。\n",
    "        *   输出获取的标签数据 (label)。\n",
    "        *   输出 `DatasetH` 的配置字典。\n",
    "\n",
    "5.  **模型训练与推断**：\n",
    "    *   输出 LightGBM 模型的配置字典。\n",
    "    *   模型训练过程中，`R.start()` 会启动一个实验记录，可能会有 MLflow 相关的日志输出。\n",
    "    *   模型训练完成后，会保存训练好的模型和预测信号 (`pred.pkl`)，并输出实验记录的 ID (`rid`)。\n",
    "\n",
    "6.  **模型评估**：\n",
    "    *   **信号分析 (Signal-based analysis)**：`SigAnaRecord` 会生成信号分析报告，结果保存在实验记录中。\n",
    "    *   **投资组合分析 (Portfolio-based analysis - 回测)**：`PortAnaRecord` 会进行回测并生成投资组合分析报告，结果保存在实验记录中。\n",
    "\n",
    "7.  **结果加载与分析**：\n",
    "    *   加载之前保存的实验记录器对象。\n",
    "    *   加载预测结果 (`pred_df`)、回测报告 (`report_normal_df`)、持仓信息 (`positions`)、投资组合详细分析 (`analysis_df`) 和训练好的模型 (`loaded_model`)，并可能打印这些对象的部分内容或类型信息。\n",
    "    *   **持仓分析 (analysis position)**：\n",
    "        *   生成并显示回测报告的**图表** (如累计收益曲线、年化收益、夏普比率等)。\n",
    "        *   生成并显示风险分析的**图表**。\n",
    "    *   **模型分析 (analysis model)**：\n",
    "        *   准备测试集的标签数据 (`label_df`)。\n",
    "        *   生成并显示**IC (信息系数) 分数图表**。\n",
    "        *   生成并显示**模型性能图表** (如Rank IC、精确度、召回率等)。\n",
    "\n",
    "总而言之，这个 Notebook 会引导你完成一个完整的量化策略开发和评估流程，并输出大量的数据、图表和分析结果，帮助你理解 Qlib 的各项功能以及量化研究的细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096c6260",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Though users can automatically run the whole Quant research worklfow based on configurations with Qlib.\n",
    "\n",
    "Some advanced users usally would like to carefully customize each component to explore more in Quant.\n",
    "\n",
    "If you just want a simple example of Qlib. [Quick start](https://github.com/microsoft/qlib#quick-start) and [workflow_by_code](https://github.com/microsoft/qlib/blob/main/examples/workflow_by_code.ipynb) may be a better choice for you.\n",
    "\n",
    "If you want to know more details about Quant research, this notebook may be a better place for you to start.\n",
    "\n",
    "We hope this script could be a tutorial for users who are interested in the details of Quant.\n",
    "\n",
    "This notebook tries to demonstrate how can we use Qlib to build components step by step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a4196",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e707694",
   "metadata": {},
   "outputs": [],
   "source": [
    "MARKET = \"csi300\"\n",
    "BENCHMARK = \"SH000300\"\n",
    "EXP_NAME = \"tutorial_exp\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff16a42b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df055d7d",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9898c23",
   "metadata": {},
   "source": [
    "Users can follow [the steps](https://github.com/microsoft/qlib/tree/main/scripts#download-qlib-data) to download data with CLI.\n",
    "\n",
    "In this example we use the underlying API to automatically download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0bcfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.tests.data import GetData\n",
    "\n",
    "GetData().qlib_data(exists_skip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b89646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qlib\n",
    "\n",
    "qlib.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90080d29",
   "metadata": {},
   "source": [
    "## Inspect raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413e99b8",
   "metadata": {},
   "source": [
    "Currently, Qlib support several kinds of data source."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf241e9",
   "metadata": {},
   "source": [
    "### Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c386f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.data import D\n",
    "\n",
    "print(D.calendar(start_time=\"2010-01-01\", end_time=\"2017-12-31\", freq=\"day\")[:2])  # calendar data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f436b49d",
   "metadata": {},
   "source": [
    "### Basic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a889b763",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = D.features(\n",
    "    [\"SH601216\"],\n",
    "    [\"$open\", \"$high\", \"$low\", \"$close\", \"$factor\"],\n",
    "    start_time=\"2020-05-01\",\n",
    "    end_time=\"2020-05-31\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceb43c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = \"notebook\"\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Candlestick(\n",
    "            x=df.index.get_level_values(\"datetime\"),\n",
    "            open=df[\"$open\"],\n",
    "            high=df[\"$high\"],\n",
    "            low=df[\"$low\"],\n",
    "            close=df[\"$close\"],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768ef188",
   "metadata": {},
   "source": [
    "### price adjustment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a536a4",
   "metadata": {},
   "source": [
    "Maybe you think the price is not what it looks like in real world.\n",
    "\n",
    "Due to the price adjustment, the price will be different from the real trading data ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45df33b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Candlestick(\n",
    "            x=df.index.get_level_values(\"datetime\"),\n",
    "            open=df[\"$open\"] / df[\"$factor\"],\n",
    "            high=df[\"$high\"] / df[\"$factor\"],\n",
    "            low=df[\"$low\"] / df[\"$factor\"],\n",
    "            close=df[\"$close\"] / df[\"$factor\"],\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6acffc3",
   "metadata": {},
   "source": [
    "Please notice the price gap on [2020-05-26](http://vip.stock.finance.sina.com.cn/corp/view/vISSUE_ShareBonusDetail.php?stockid=601216&type=1&end_date=2020-05-20)\n",
    "\n",
    "If we want to represent the change of assets value by price, adjust prices are necesary.\n",
    "By default, Qlib stores the adjusted prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5f063e",
   "metadata": {},
   "source": [
    "### Static universe V.S. dynamic universe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9b8ce5",
   "metadata": {},
   "source": [
    "Dynamic universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d3ab70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dynamic universe\n",
    "universe = D.list_instruments(D.instruments(\"csi100\"), start_time=\"2010-01-01\", end_time=\"2020-12-31\")\n",
    "pprint(universe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be08f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(universe))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e7dd04",
   "metadata": {},
   "source": [
    "Qlib use dynamic universe by default.\n",
    "\n",
    "csi100 has around 100 stocks each day(it is not that accurate due to the low precision of data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = D.features(D.instruments(\"csi100\"), [\"$close\"], start_time=\"2010-01-01\", end_time=\"2020-12-31\")\n",
    "df.groupby(\"datetime\").size().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f37f2ef",
   "metadata": {},
   "source": [
    "### Point-In-Time data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfa9e9d",
   "metadata": {},
   "source": [
    "#### download data\n",
    "NOTE: To run the test faster, we only download the data of two stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0a9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path(\"~/.qlib/qlib_data/cn_data/financial\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4657fe13",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not p.exists():\n",
    "    !cd ../../scripts/data_collector/pit/ && pip install -r requirements.txt\n",
    "    !cd ../../scripts/data_collector/pit/ && python collector.py download_data --source_dir ~/.qlib/stock_data/source/pit --start 2000-01-01 --end 2020-01-01 --interval quarterly --symbol_regex \"^(600519|000725).*\"\n",
    "    !cd ../../scripts/data_collector/pit/ && python collector.py normalize_data --interval quarterly --source_dir ~/.qlib/stock_data/source/pit --normalize_dir ~/.qlib/stock_data/source/pit_normalized\n",
    "    !cd ../../scripts/ && python dump_pit.py dump --csv_path ~/.qlib/stock_data/source/pit_normalized --qlib_dir ~/.qlib/qlib_data/cn_data --interval quarterly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9358cb89",
   "metadata": {},
   "source": [
    "#### querying data\n",
    "using `roewa(performanceExpressROEWa,业绩快报净资产收益率ROE-加权)` as an example\n",
    "\n",
    "If we want to get fundamental data `in the most recent quarter` daily, we can use following example.\n",
    "\n",
    "Maitai release part of its fundamental data on [2019-07-13](http://www.cninfo.com.cn/new/disclosure/detail?stockCode=600519&announcementId=1206443183&orgId=gssh0600519&announcementTime=2019-07-13) and  release others on [2019-07-18](http://www.cninfo.com.cn/new/disclosure/detail?stockCode=600519&announcementId=1206456129&orgId=gssh0600519&announcementTime=2019-07-18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ee1621",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruments = [\"sh600519\"]\n",
    "data = D.features(\n",
    "    instruments,\n",
    "    [\"P($$roewa_q)\"],\n",
    "    start_time=\"2019-01-01\",\n",
    "    end_time=\"2019-07-19\",\n",
    "    freq=\"day\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752f4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e370d2d",
   "metadata": {},
   "source": [
    "### experss engine\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d166c",
   "metadata": {},
   "outputs": [],
   "source": [
    "D.features(\n",
    "    [\"sh600519\"],\n",
    "    [\"(EMA($close, 12) - EMA($close, 26))/$close - EMA((EMA($close, 12) - EMA($close, 26))/$close, 9)/$close\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddcd1ea",
   "metadata": {},
   "source": [
    "\n",
    "## Dataset loading and preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54c6804",
   "metadata": {},
   "source": [
    "Some heuristic principles of create features\n",
    "- make the features comparable between instrumets: remove unit from the features.\n",
    "- try to keep the distribution invariant\n",
    "- keep the scale of features similar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93013dcd",
   "metadata": {},
   "source": [
    "### data loader\n",
    "\n",
    "It's interface can be found [here](https://github.com/microsoft/qlib/blob/main/qlib/data/dataset/loader.py#L24) \n",
    "\n",
    "QlibDataLoader is an implementation which load data from Qlib's data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcfa44a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.data.dataset.loader import QlibDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdl = QlibDataLoader(config=([\"$close / Ref($close, 10)\"], [\"RET10\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb29d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qdl.load(instruments=[\"sh600519\"], start_time=\"20190101\", end_time=\"20191231\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dded8f5",
   "metadata": {},
   "source": [
    "### data handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d6d2b0",
   "metadata": {},
   "source": [
    "finance data can't be perfect.\n",
    "\n",
    "We have to process them before feeding them into Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c078fa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = qdl.load(instruments=[\"sh600519\"], start_time=\"20190101\", end_time=\"20191231\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e5adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514b85e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1625f7",
   "metadata": {},
   "source": [
    "Datahander is responsible for data preprocessing and provides data fetching interface \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b35c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.data.dataset.handler import DataHandlerLP\n",
    "from qlib.data.dataset.processor import ZScoreNorm, Fillna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a5f4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: normally, the training & validation time range will be  `fit_start_time` ， `fit_end_time`\n",
    "# however，all the components are decomposed, so the training & validation time range is unknown when preprocessing.\n",
    "dh = DataHandlerLP(\n",
    "    instruments=[\"sh600519\"],\n",
    "    start_time=\"20170101\",\n",
    "    end_time=\"20191231\",\n",
    "    infer_processors=[\n",
    "        ZScoreNorm(fit_start_time=\"20170101\", fit_end_time=\"20181231\"),\n",
    "        Fillna(),\n",
    "    ],\n",
    "    data_loader=qdl,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9469fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dh.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35b3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8e11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7208efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0fb32c",
   "metadata": {},
   "source": [
    "### dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0302a801",
   "metadata": {},
   "source": [
    "#### basic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ef76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.data.dataset import DatasetH, TSDatasetH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fd8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = DatasetH(dh, segments={\"train\": (\"20180101\", \"20181231\"), \"valid\": (\"20190101\", \"20191231\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc4c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4639b6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.prepare(\"valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56001e4",
   "metadata": {},
   "source": [
    "#### Time Series Dataset\n",
    "\n",
    "For different model, the required dataset format will be different.\n",
    "\n",
    "For example, Qlib provides a Time Series Dataset(TSDatasetH) to help users to create time-series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425135e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TSDatasetH(\n",
    "    step_len=10,\n",
    "    handler=dh,\n",
    "    segments={\"train\": (\"20180101\", \"20181231\"), \"valid\": (\"20190101\", \"20191231\")},\n",
    ")\n",
    "train_sampler = ds.prepare(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f724041",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5aa762c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler[0]  # Retrieving the first example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb64112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler[\"2018-01-08\", \"sh600519\"]  # get the time series by <'timestamp', 'instrument_id'> index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6ab197",
   "metadata": {},
   "source": [
    "### Off-the-shelf dataset\n",
    "\n",
    "Qlib integrated some dataset alreadly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e21b45c",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "handler_kwargs = {\n",
    "    \"start_time\": \"2008-01-01\",\n",
    "    \"end_time\": \"2020-08-01\",\n",
    "    \"fit_start_time\": \"2008-01-01\",\n",
    "    \"fit_end_time\": \"2014-12-31\",\n",
    "    \"instruments\": MARKET,\n",
    "}\n",
    "handler_conf = {\n",
    "    \"class\": \"Alpha158\",\n",
    "    \"module_path\": \"qlib.contrib.data.handler\",\n",
    "    \"kwargs\": handler_kwargs,\n",
    "}\n",
    "pprint(handler_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17077f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.utils import init_instance_by_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a20d9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd = init_instance_by_config(handler_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa02379",
   "metadata": {},
   "source": [
    "Using config to create instance is a highly frequently used practice in Qlib (e.g. the [workflows configurations](https://github.com/microsoft/qlib/blob/main/examples/benchmarks/LightGBM/workflow_config_lightgbm_Alpha158.yaml) are based on it).\n",
    "\n",
    "\n",
    "The above configuration is the same as the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480d35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.contrib.data.handler import Alpha158\n",
    "\n",
    "hd = Alpha158(**handler_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b170153d",
   "metadata": {},
   "source": [
    "This dataset has the same structure as the simple one with 1 column  we created just now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735758e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hd.fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6de50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1bc4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a927f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.data_loader.fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a15747",
   "metadata": {},
   "source": [
    "#### some details\n",
    "\n",
    "The training data may not be the same as the test data.\n",
    "\n",
    "e.g.\n",
    "- the training dataset and test dataset use a different fitlering rules,  data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2defa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.learn_processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55a881",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.infer_processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af3b077",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.process_type  # appending type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20127e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.fetch(col_set=\"label\", data_key=hd.DK_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c37d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "hd.fetch(col_set=\"label\", data_key=hd.DK_I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2cfb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_conf = {\n",
    "    \"class\": \"DatasetH\",\n",
    "    \"module_path\": \"qlib.data.dataset\",\n",
    "    \"kwargs\": {\n",
    "        \"handler\": hd,\n",
    "        \"segments\": {\n",
    "            \"train\": (\"2008-01-01\", \"2014-12-31\"),\n",
    "            \"valid\": (\"2015-01-01\", \"2016-12-31\"),\n",
    "            \"test\": (\"2017-01-01\", \"2020-08-01\"),\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca33c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = init_instance_by_config(dataset_conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c89c15d",
   "metadata": {},
   "source": [
    "# Model Training & Inference\n",
    "\n",
    "[Model interface](https://github.com/microsoft/qlib/blob/main/qlib/model/base.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e916286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.workflow import R\n",
    "from qlib.workflow.record_temp import SignalRecord, PortAnaRecord, SigAnaRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6975911",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_instance_by_config(\n",
    "    {\n",
    "        \"class\": \"LGBModel\",\n",
    "        \"module_path\": \"qlib.contrib.model.gbdt\",\n",
    "        \"kwargs\": {\n",
    "            \"loss\": \"mse\",\n",
    "            \"colsample_bytree\": 0.8879,\n",
    "            \"learning_rate\": 0.0421,\n",
    "            \"subsample\": 0.8789,\n",
    "            \"lambda_l1\": 205.6999,\n",
    "            \"lambda_l2\": 580.9768,\n",
    "            \"max_depth\": 8,\n",
    "            \"num_leaves\": 210,\n",
    "            \"num_threads\": 20,\n",
    "        },\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2dafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start exp to train model\n",
    "with R.start(experiment_name=EXP_NAME):\n",
    "    model.fit(dataset)\n",
    "    R.save_objects(trained_model=model)\n",
    "\n",
    "    rec = R.get_recorder()\n",
    "    rid = rec.id  # save the record id\n",
    "\n",
    "    # Inference and saving signal\n",
    "    sr = SignalRecord(model, dataset, rec)\n",
    "    sr.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6b9f3d",
   "metadata": {},
   "source": [
    "# Evaluation:\n",
    "- Signal-based\n",
    "- Portfolio-based: backtest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# prediction, backtest & analysis\n",
    "###################################\n",
    "port_analysis_config = {\n",
    "    \"executor\": {\n",
    "        \"class\": \"SimulatorExecutor\",\n",
    "        \"module_path\": \"qlib.backtest.executor\",\n",
    "        \"kwargs\": {\n",
    "            \"time_per_step\": \"day\",\n",
    "            \"generate_portfolio_metrics\": True,\n",
    "        },\n",
    "    },\n",
    "    \"strategy\": {\n",
    "        \"class\": \"TopkDropoutStrategy\",\n",
    "        \"module_path\": \"qlib.contrib.strategy.signal_strategy\",\n",
    "        \"kwargs\": {\n",
    "            \"signal\": \"<PRED>\",\n",
    "            \"topk\": 50,\n",
    "            \"n_drop\": 5,\n",
    "        },\n",
    "    },\n",
    "    \"backtest\": {\n",
    "        \"start_time\": \"2017-01-01\",\n",
    "        \"end_time\": \"2020-08-01\",\n",
    "        \"account\": 100000000,\n",
    "        \"benchmark\": BENCHMARK,\n",
    "        \"exchange_kwargs\": {\n",
    "            \"freq\": \"day\",\n",
    "            \"limit_threshold\": 0.095,\n",
    "            \"deal_price\": \"close\",\n",
    "            \"open_cost\": 0.0005,\n",
    "            \"close_cost\": 0.0015,\n",
    "            \"min_cost\": 5,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "# backtest and analysis\n",
    "with R.start(experiment_name=EXP_NAME, recorder_id=rid, resume=True):\n",
    "    # signal-based analysis\n",
    "    rec = R.get_recorder()\n",
    "    sar = SigAnaRecord(rec)\n",
    "    sar.generate()\n",
    "\n",
    "    #  portfolio-based analysis: backtest\n",
    "    par = PortAnaRecord(rec, port_analysis_config, \"day\")\n",
    "    par.generate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66ad59d",
   "metadata": {},
   "source": [
    "# Loading results & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7d7dea",
   "metadata": {},
   "source": [
    "## loading data\n",
    "Because Qlib leverage MLflow to save model & data.\n",
    "All the data can be access by `mlflow ui`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec9dbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load recorder\n",
    "recorder = R.get_recorder(recorder_id=rid, experiment_name=EXP_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e72b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previous results\n",
    "pred_df = recorder.load_object(\"pred.pkl\")\n",
    "report_normal_df = recorder.load_object(\"portfolio_analysis/report_normal_1day.pkl\")\n",
    "positions = recorder.load_object(\"portfolio_analysis/positions_normal_1day.pkl\")\n",
    "analysis_df = recorder.load_object(\"portfolio_analysis/port_analysis_1day.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce3696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Previous Model can be loaded. but it is not used.\n",
    "loaded_model = recorder.load_object(\"trained_model\")\n",
    "loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8eca78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlib.contrib.report import analysis_model, analysis_position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d34b347",
   "metadata": {},
   "source": [
    "## analysis position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae642f",
   "metadata": {},
   "source": [
    "### report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c727b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.report_graph(report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b7ca14",
   "metadata": {},
   "source": [
    "### risk analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f100690",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_position.risk_analysis_graph(analysis_df, report_normal_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed48aee",
   "metadata": {},
   "source": [
    "## analysis model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec13561",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = dataset.prepare(\"test\", col_set=\"label\")\n",
    "label_df.columns = [\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d57363",
   "metadata": {},
   "source": [
    "### score IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7612533d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = pd.concat([label_df, pred_df], axis=1, sort=True).reindex(label_df.index)\n",
    "analysis_position.score_ic_graph(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589664c4",
   "metadata": {},
   "source": [
    "### model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40258655",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_model.model_performance_graph(pred_label)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
